hadoop distcp  集群间互拷，需hdfs-site.xml配置
hadoop distcp OPTIONS [source_path...] <target_path>
-----------------------------------------------------
如果一个文件非常大，而且只有一行(比如mysql dump文件)，可以使用sed 找到共性，切割为多行，然后用hadoop处理成格式化数据
-----------------------------------------------------
hbase 迁移表数据 
1、暂停表相关的业务，读写, 并flush 内存的数据 flush “test1”
2、copy表结构，包括regions配置，自己写读取原表的源数据
3、原来的表做major_compact
4、disable 表
5、在新集群新建目录，比如/tmp/bulkload
6、在新集群创建表[包含了region信息]
7、选择namenode[active 状态的节点] 比如   NameNode, nfjd-hbase01-node15 (Active)
8、可能会遇到没有write权限，需要在/user下创建权限
     sudo su - hdfs  然后 hadoop fs -mkdir /user/alex ; hadoop fs -chown zhuolin:users /user/alex  两个集群都需要
     执行distcp hadoop distcp hdfs://nameservice-hbase1/hbase/data/default/test1 hdfs://localhost/tmp/bulkload
9、然后修改权限 hdfs dfs -chown -R hbase:hbase /tmp/bulkload/
10、执行 ./bulkload.sh
------------------------------------------------------
kylin 统计
为了减少cuboid的数目，kylin将Dimension分成4中类型
1、Normal，为最常见的类型，与所有其他的dimension组合构成cuboid。
2、Mandatory，在每一次查询中都会用到dimension，
3、Hierarchy，为带层级的dimension，比如说：省份->城市， 年->季度->月->周->日；以用于做drill down 
4、Derived，指该dimensions与维表的primary key是一一对应关系，可以更有效地减少cuboid数量
------------------------------------------------------
cloudera manager 修改NameNode Nameservice, 重启的时候两个NameNode 都是standby状态
因为NameNode向zookeeper注册不上，可以登录zookeeper_client查看ls /hadoop-ha 看新的NameNode Nameservice有没有生成
执行 sudo -u hdfs hdfs zkfc -formatZK 
------------------------------------------------------
Reducer 的 Iterable<Text> values 只能遍历一次
-----------------------------------------------
卸载CDH5.7.1步骤：
1、选择hosts，关掉hosts所有roles[一般顺序是HIVE、MR、hbase、hdfs、zookeeper,最后一个个删除依赖服务]
2、然后操作Hosts Decommissioned，然后执行delete，依赖顺序hue,oozie,hive,hbase,hdfs,zookeeper
3、然后disactive parcels
4、delete cluster
5、sudo service cloudera-scm-agent stop , sudo service cloudera-scm-server stop, sudo service cloudera-scm-server-db stop
6、sudo rm -rf /usr/share/cmf/ /var/lib/cloudera* /var/cache/yum/x86_64/7/cloudera-manager/
7、sudo rm -rf /var/lib/flume-ng/ /var/lib/hadoop* /var/lib/oozie/ /var/lib/solr/ /var/lib/sqoop* /var/lib/hue /var/lib/zookeeper/ /var/lib/hbase/ /var/lib/hive/ /var/lib/impala/ 
8、sudo rm -rf /var/log/zookeeper /var/log/cloudera* /var/log/hbase /var/log/hadoop* /opt/cloudera /etc/hadoop/ /etc/hbase/ /etc/hive/ /etc/cloudera-scm-agent/
9、清理yum源 sudo yum remove 'cloudera-manager*' , sudo yum clean all
10、卸载挂载 sudo umount cm_processes
11、卸载mysql或者pg  /usr/local/pgsql8.4/bin/pg_ctl -D /usr/local/pgsql8.4/data stop
12、清空磁盘 sudo rm -rf /hdfs00/* /hdfs01/* /hdfs02/* /hdfs03/* /hdfs04/*
-------------------------------------------------
测试hdfs IO
hadoop jar hadoop-mapreduce-client-jobclient-2.6.0.jar TestDFSIO -write -nrFiles 10 -size 50MB
hadoop jar hadoop-mapreduce-client-jobclient-2.6.0.jar TestDFSIO -read -nrFiles 10 -size 50MB
	
------------- NTP --------------
sudo /bin/systemctl restart  ntpd.service 查看下NTP是否启动( 这是老的 )
Centos7命令： sudo systemctl enable ntpd 、 sudo systemctl start ntpd | 查看状态 ntpstat
    
-------------- 配置机器脚本 ----------------------
1、disable_THP.sh 
if [[  -f /sys/kernel/mm/redhat_transparent_hugepage/enabled ]]; then
    echo never > /sys/kernel/mm/redhat_transparent_hugepage/enabled
    echo never > /sys/kernel/mm/redhat_transparent_hugepage/defrag
elif [[ -f /sys/kernel/mm/transparent_hugepage/enabled ]]; then
    echo never > /sys/kernel/mm/transparent_hugepage/enabled
    echo never > /sys/kernel/mm/transparent_hugepage/defrag
fi
--------------------------------------------------------
空间不够，可以设置目录副本数，hadoop dfs -setrep -w 2 -R /hbase/data/default/userprofile_imei，改成两个副本
----实时同步hbase----
REPLICATION_SCOPE=>'1' 不需要disable table
1、add_peer '6','nfjd-hbase01-node01.jpushoa.com,nfjd-hbase01-node02.jpushoa.com,nfjd-hbase01-node03.jpushoa.com:2181:/hbase'
2、立即 disable_peer '6'
3、 snapshot 'zl_test_tb', 'zl_test_tb_snapshot_6'
4、拷贝snapshot: hbase org.apache.hadoop.hbase.snapshot.ExportSnapshot -snapshot zl_test_tb_snapshot_6 -copy-to hdfs://nfjd-hbase01-node09.jpushoa.com:8020/hbase -mappers 6 -bandwidth 100
5、在目标集群创建表：create 'zl_test_tb',{NAME => 'A', VERSIONS => '10000',REPLICATION_SCOPE=>'1'}
6、在目的集群修改权限和恢复snapshot:
hadoop fs -chmod -R 777 /hbase/.hbase-snapshot/
hadoop fs -chmod -R 777 /hbase/archive/data/default/zl_test_tb
7、disable 'zl_test_tb' 然后 restore_snapshot 'zl_test_tb_snapshot_6', 然后enable 'zl_test_tb'
8、enable_peer '6'

注意：如果不停止oldWALs数据量会增长很快，需要remove_peer 
http://stackoverflow.com/questions/28725364/hbase-oldwals-what-it-is-and-how-can-i-clean-it
---- hbase 处理 is not online region 和 某些key 不在start和end之间  -----
hbase hbck -repair
hbase hbck -repairHole
