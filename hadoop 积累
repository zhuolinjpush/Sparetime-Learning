hadoop distcp  集群间互拷，需hdfs-site.xml配置
hadoop distcp OPTIONS [source_path...] <target_path>
-----------------------------------------------------
如果一个文件非常大，而且只有一行(比如mysql dump文件)，可以使用sed 找到共性，切割为多行，然后用hadoop处理成格式化数据
-----------------------------------------------------
hbase 迁移表数据 
1、暂停表相关的业务，读写, 并flush 内存的数据 flush “test1”
2、copy表结构，包括regions配置，自己写读取原表的源数据
3、原来的表做major_compact
4、disable 表
5、在新集群新建目录，比如/tmp/bulkload
6、在新集群创建表[包含了region信息]
7、选择namenode[active 状态的节点] 比如   NameNode, nfjd-hbase01-node15 (Active)
8、可能会遇到没有write权限，需要在/user下创建权限
     sudo su - hdfs  然后 hadoop fs -mkdir /user/alex ; hadoop fs -chown zhuolin:users /user/alex  两个集群都需要
     执行distcp hadoop distcp hdfs://nameservice-hbase1/hbase/data/default/test1 hdfs://localhost/tmp/bulkload
9、然后修改权限 hdfs dfs -chown -R hbase:hbase /tmp/bulkload/
10、执行 ./bulkload.sh
------------------------------------------------------
kylin 统计
为了减少cuboid的数目，kylin将Dimension分成4中类型
1、Normal，为最常见的类型，与所有其他的dimension组合构成cuboid。
2、Mandatory，在每一次查询中都会用到dimension，
3、Hierarchy，为带层级的dimension，比如说：省份->城市， 年->季度->月->周->日；以用于做drill down 
4、Derived，指该dimensions与维表的primary key是一一对应关系，可以更有效地减少cuboid数量
------------------------------------------------------
cloudera manager 修改NameNode Nameservice, 重启的时候两个NameNode 都是standby状态
因为NameNode向zookeeper注册不上，可以登录zookeeper_client查看ls /hadoop-ha 看新的NameNode Nameservice有没有生成
执行 sudo -u hdfs hdfs zkfc -formatZK 
------------------------------------------------------
Reducer 的 Iterable<Text> values 只能遍历一次
-----------------------------------------------
卸载CDH5.7.1步骤：
1、选择hosts，关掉hosts所有roles[一般顺序是HIVE、MR、hbase、hdfs、zookeeper,最后一个个删除依赖服务]
2、然后操作Hosts Decommissioned，然后执行delete，依赖顺序hue,oozie,hive,hbase,hdfs,zookeeper
3、然后disactive parcels
4、delete cluster
5、sudo service cloudera-scm-agent stop , sudo service cloudera-scm-server stop, sudo service cloudera-scm-server-db stop
6、sudo rm -rf /usr/share/cmf/ /var/lib/cloudera* /var/cache/yum/x86_64/7/cloudera-manager/
7、sudo rm -rf /var/lib/flume-ng/ /var/lib/hadoop* /var/lib/oozie/ /var/lib/solr/ /var/lib/sqoop* /var/lib/hue /var/lib/zookeeper/ /var/lib/hbase/ /var/lib/hive/ /var/lib/impala/ 
8、sudo rm -rf /var/log/zookeeper /var/log/cloudera* /var/log/hbase /var/log/hadoop* /opt/cloudera /etc/hadoop/ /etc/hbase/ /etc/hive/ /etc/cloudera-scm-agent/
9、清理yum源 sudo yum remove 'cloudera-manager*' , sudo yum clean all
10、卸载挂载 sudo umount cm_processes
11、卸载mysql或者pg  /usr/local/pgsql8.4/bin/pg_ctl -D /usr/local/pgsql8.4/data stop
12、清空磁盘 sudo rm -rf /hdfs00/* /hdfs01/* /hdfs02/* /hdfs03/* /hdfs04/*
-------------------------------------------------
测试hdfs IO
hadoop jar hadoop-mapreduce-client-jobclient-2.6.0.jar TestDFSIO -write -nrFiles 10 -size 50MB
hadoop jar hadoop-mapreduce-client-jobclient-2.6.0.jar TestDFSIO -read -nrFiles 10 -size 50MB
	
     
     
     
     
     
-------------- 配置机器脚本 ----------------------
1、disable_THP.sh 
if [[  -f /sys/kernel/mm/redhat_transparent_hugepage/enabled ]]; then
    echo never > /sys/kernel/mm/redhat_transparent_hugepage/enabled
    echo never > /sys/kernel/mm/redhat_transparent_hugepage/defrag
elif [[ -f /sys/kernel/mm/transparent_hugepage/enabled ]]; then
    echo never > /sys/kernel/mm/transparent_hugepage/enabled
    echo never > /sys/kernel/mm/transparent_hugepage/defrag
fi
--------------------------------------------------------
